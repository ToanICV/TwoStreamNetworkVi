task: S2T
data:
  dataset_name: vsl-edu
  zip_file: /kaggle/working/vsl-edu.zip
  train: /kaggle/input/vsl-edu-labels/myVSL.train
  dev: /kaggle/input/vsl-edu-labels/myVSL.dev
  test: /kaggle/input/vsl-edu-labels/myVSL.test
  dev_head_rgb_input: /kaggle/working/TwoStreamNetworkVi/TwoStreamNetwork/experiments/outputs/SingleStream/vsl-edu_s2g/extract_feature/head_rgb_input/dev.pkl
  test_head_rgb_input: /kaggle/working/TwoStreamNetworkVi/TwoStreamNetwork/experiments/outputs/SingleStream/vsl-edu_s2g/extract_feature/head_rgb_input/test.pkl
  train_head_rgb_input: /kaggle/working/TwoStreamNetworkVi/TwoStreamNetwork/experiments/outputs/SingleStream/vsl-edu_s2g/extract_feature/head_rgb_input/train.pkl
  input_data: videos
  input_streams:
  - rgb
  level: word
  max_sent_length: 400
  txt_lowercase: true
testing:
  cfg:
    recognition:
      beam_size: 1
    translation:
      length_penalty: 1
      max_length: 500
      num_beams: 5
training:
  batch_size: 8
  keep_last_ckpts: 1
  model_dir: experiments/outputs/SingleStream/vsl-edu_s2t
  num_workers: 4
  optimization:
    betas:
    - 0.9
    - 0.998
    learning_rate:
      default: 0.0001
      translation: 1.0e-05
    optimizer: Adam
    scheduler: cosineannealing
    t_max: 40
    weight_decay: 0.001
  overwrite: true
  random_seed: 0
  shuffle: true
  total_epoch: 40
  validation:
    cfg:
      recognition:
        beam_size: 1
      translation:
        length_penalty: 1
        max_length: 60
        num_beams: 4
    freq: 1
    unit: epoch
model:
  RecognitionNetwork:
    GlossTokenizer:
      # gloss2id_file: /kaggle/input/vsl-edu-labels/gloss2ids_vsl.pkl
      gloss2id_file: /kaggle/working/TwoStreamNetworkVi/TwoStreamNetwork/pretrained_models/pretrained_models_mBart/gloss2ids.pkl
    fuse_method: empty
    gloss_feature_ensemble: gloss_probabilities
    heatmap_cfg:
      input_size: 112
      map_size:
      - 170
      - 170
      raw_size:
      - 512
      - 512
      sigma: 8
      threshold: 0.5
    s3d:
      freeze_block: 1
      pretrained_ckpt: pretrained_models/s3ds_glosscls_ckpt
      use_block: 4
    visual_head:
      ff_kernelsize:
      - 3
      - 3
      ff_size: 2048
      hidden_size: 512
      input_size: 832
      pe: true
  TranslationNetwork:
    GlossEmbedding:
      gloss2embed_file: /kaggle/working/TwoStreamNetworkVi/TwoStreamNetwork/pretrained_models/pretrained_models_mBart/gloss_embeddings.bin
    GlossTokenizer:
      # gloss2id_file: /kaggle/input/vsl-edu-labels/gloss2ids_vsl.pkl
      gloss2id_file: /kaggle/working/TwoStreamNetworkVi/TwoStreamNetwork/pretrained_models/pretrained_models_mBart/gloss2ids.pkl
      src_lang: vi_VSL
    TextTokenizer:
      pretrained_model_name_or_path: /kaggle/working/TwoStreamNetworkVi/TwoStreamNetwork/pretrained_models/pretrained_models_mBart/
      pruneids_file: /kaggle/working/TwoStreamNetworkVi/TwoStreamNetwork/pretrained_models/pretrained_models_mBart/map_ids.pkl
      tgt_lang: vi_VN
    freeze_txt_embed: false
    label_smoothing: 0.2
    overwrite_cfg:
      attention_dropout: 0.1
      dropout: 0.3
    pretrained_model_name_or_path: /kaggle/working/TwoStreamNetworkVi/TwoStreamNetwork/pretrained_models/pretrained_models_mBart/ 
    load_ckpt: experiments/outputs/SingleStream/vsl-edu_g2t/best.ckpt
  VLMapper:
    freeze: false
    type: embedding
